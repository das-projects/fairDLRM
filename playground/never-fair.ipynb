{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification that is never fair\n",
    "\n",
    "In this notebook we try to train a fair classifier on a dataset that is inherently unfair; i.e. the\n",
    "base rate varies between the protected classes. The dataset is generated in `gen-unfair-data.ipynb`.\n",
    "The idea behind this notebook is that is impossible to create such a classifier which is fair in\n",
    "false positives (i.e. people who get tagged but should not be) as well as false negatives (people\n",
    "who should be tagged but aren't) **and** performs better than random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from IPython import display\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(7)\n",
    "sns.set(style=\"white\", palette=\"muted\", color_codes=True, context=\"talk\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDE\n",
    "def load_GEN_data(path):\n",
    "    input_data = pd.read_csv(path)\n",
    "    \n",
    "    # sensitive attributes; we identify 'race' and 'sex' as sensitive attributes\n",
    "    sensitive_attribs = ['protected']\n",
    "    Z = (input_data.loc[:, sensitive_attribs]\n",
    "         .assign(protected=lambda df: (df['protected'] == 'B').astype(int)))\n",
    "\n",
    "    # targets; 1 when someone makes over 50k , otherwise 0\n",
    "    y = input_data['target'].astype(int)\n",
    "\n",
    "    # features; note that the 'target' and sentive attribute columns are dropped\n",
    "    X = (input_data\n",
    "         .drop(columns=['target', 'protected'])\n",
    "         .pipe(pd.get_dummies, drop_first=True))\n",
    "    \n",
    "    print(f\"features X: {X.shape[0]} samples, {X.shape[1]} attributes\")\n",
    "    print(f\"targets y: {y.shape} samples\")\n",
    "    print(f\"sensitives Z: {Z.shape[0]} samples, {Z.shape[1]} attributes\")\n",
    "    return X, y, Z\n",
    "\n",
    "\n",
    "def p_rule(y_pred, z_values, threshold=0.5):\n",
    "    y_z_1 = y_pred[z_values == 1] > threshold if threshold else y_pred[z_values == 1]\n",
    "    y_z_0 = y_pred[z_values == 0] > threshold if threshold else y_pred[z_values == 0]\n",
    "    odds = y_z_1.mean() / y_z_0.mean()\n",
    "    return np.min([odds, 1/odds]) * 100\n",
    "\n",
    "def fp_rate(y_test, y_pred, z_values, threshold=0.5):\n",
    "    z_1 = y_pred[(y_test == False) & (z_values == 1)]\n",
    "    z_0 = y_pred[(y_test == False) & (z_values == 0)]\n",
    "    return {0: (z_0 > threshold).sum() / len(z_0), 1:(z_1 > threshold).sum() / len(z_1)}\n",
    "\n",
    "def fn_rate(y_test, y_pred, z_values, threshold=0.5):\n",
    "    z_1 = y_pred[(y_test == True) & (z_values == 1)]\n",
    "    z_0 = y_pred[(y_test == True) & (z_values == 0)]\n",
    "    return {0: (z_0 <= threshold).sum() / len(z_0), 1:(z_1 <= threshold).sum() / len(z_1)}\n",
    "\n",
    "def plot_dists(y_true, Z_true, y_pred, Z_pred=None, epoch=None):\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 4), sharey=True)\n",
    "    \n",
    "    subplot_df = (\n",
    "        Z_true\n",
    "        .assign(protected=lambda x: x['protected'].map({1: 'B', 0: 'A'}))\n",
    "        #.assign(sex=lambda x: x['sex'].map({1: 'male', 0: 'female'}))\n",
    "        .assign(y_pred=y_pred)\n",
    "        .assign(y_true=y_true)\n",
    "    )\n",
    "    _subplot(subplot_df, 'protected', ax=axes[0])\n",
    "    _subplot(subplot_df, 'y_true', ax=axes[1])\n",
    "    _performance_text(fig, y_true, Z_true, y_pred, Z_pred, epoch)\n",
    "    fig.tight_layout()\n",
    "    \n",
    "\n",
    "def _subplot(subplot_df, col, ax):\n",
    "    for label, df in subplot_df.groupby(col):\n",
    "        sns.kdeplot(df['y_pred'], ax=ax, label=label, shade=True)\n",
    "    ax.set_title(f'Sensitive attribute: {col}')\n",
    "    ax.set_xlim(0,1)\n",
    "    ax.set_ylim(0,7)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_ylabel('Prediction distribution')\n",
    "    ax.set_xlabel(r'$P(target)$'.format(col))\n",
    "\n",
    "def _performance_text(fig, y_test, Z_test, y_pred, Z_pred=None,\n",
    "                     epoch=None):   \n",
    "\n",
    "    if epoch is not None:\n",
    "        fig.text(1.0, 0.9, f\"Training epoch #{epoch}\", fontsize='16')\n",
    "\n",
    "    clf_roc_auc = metrics.roc_auc_score(y_test, y_pred)\n",
    "    clf_accuracy = metrics.accuracy_score(y_test, y_pred > 0.5) * 100\n",
    "    p_rules = {'protected': p_rule(y_pred, Z_test['protected'])}\n",
    "    fp_rates = fp_rate(y_test, y_pred, Z_test['protected'])\n",
    "    fn_rates = fn_rate(y_test, y_pred, Z_test['protected'])\n",
    "    fig.text(1.0, 0.65, '\\n'.join([\"Classifier performance:\",\n",
    "                                   f\"- ROC AUC: {clf_roc_auc:.2f}\",\n",
    "                                   f\"- Accuracy: {clf_accuracy:.1f}\"]),\n",
    "             fontsize='16')\n",
    "    fig.text(0.35, 0.6, '\\n'.join([\"FP-rates:\"] +\n",
    "                                 [f\"- {attr}: {100*fp_rates[attr]:.2f}%\" \n",
    "                                  for attr in fp_rates.keys()]), \n",
    "             fontsize='16')\n",
    "    fig.text(0.35, 0.4, '\\n'.join([\"FN-rates:\"] +\n",
    "                                 [f\"- {attr}: {100*fn_rates[attr]:.2f}%\" \n",
    "                                  for attr in fn_rates.keys()]), \n",
    "             fontsize='16')\n",
    "    fig.text(1.0, 0.4, '\\n'.join([\"Satisfied p%-rules:\"] +\n",
    "                                 [f\"- {attr}: {p_rules[attr]:.0f}%-rule\" \n",
    "                                  for attr in p_rules.keys()]), \n",
    "             fontsize='16')\n",
    "    if Z_pred is not None:\n",
    "        adv_roc_auc = metrics.roc_auc_score(Z_test, Z_pred)\n",
    "        fig.text(1.0, 0.20, '\\n'.join([\"Adversarial performance:\",\n",
    "                               f\"- ROC AUC: {adv_roc_auc:.2f}\"]),\n",
    "                                 fontsize='16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ICU data set\n",
    "X, y, Z = load_GEN_data('data/generated.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train/test set\n",
    "X_train, X_test, y_train, y_test, Z_train, Z_test = train_test_split(X, y, Z, test_size=0.5, \n",
    "                                                                     stratify=y, random_state=7)\n",
    "\n",
    "# standardize the data\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "scale_df = lambda df, scaler: pd.DataFrame(scaler.transform(df), columns=df.columns, index=df.index)\n",
    "X_train = X_train.pipe(scale_df, scaler) \n",
    "X_test = X_test.pipe(scale_df, scaler) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenDataset(TensorDataset):\n",
    "\n",
    "    def __init__(self, X, y, Z):\n",
    "        X = torch.from_numpy(X.as_matrix()).float()\n",
    "        y = torch.from_numpy(y.to_frame('y').as_matrix()).float()\n",
    "        Z = torch.from_numpy(Z.as_matrix()).float()\n",
    "        super(GenDataset, self).__init__(X, y, Z)\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.Z = Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = GenDataset(X_train, y_train, Z_train)\n",
    "test_data = GenDataset(X_test, y_test, Z_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_features, n_hidden=32, p_dropout=0.2):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.dropout = nn.Dropout(p_dropout)\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(n_features, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            self.dropout,\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            self.dropout,\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            self.dropout,\n",
    "            nn.Linear(n_hidden, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.sigmoid(self.out(x))\n",
    "    \n",
    "\n",
    "def pretrain_classifier(clf, data_loader, optimizer, criterion):\n",
    "    for x, y, _ in data_loader:\n",
    "        clf.zero_grad()\n",
    "        p_y = clf(x)\n",
    "        loss = criterion(p_y, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Classifier(X_train.shape[1])\n",
    "clf_criterion = nn.BCELoss()\n",
    "clf_optimizer = optim.Adam(clf.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_CLF_EPOCHS = 50\n",
    "\n",
    "for epoch in range(N_CLF_EPOCHS):\n",
    "    clf = pretrain_classifier(clf, train_loader, clf_optimizer, clf_criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pre_clf_test = clf(test_data.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pre_clf = pd.Series(pre_clf_test.data.numpy().ravel(),\n",
    "                      index=y_test.index)\n",
    "_ = plot_dists(y_test, Z_test, y_pre_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adverserial(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_sensitive, n_hidden=32):\n",
    "        super(Adverserial, self).__init__()\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(1, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_sensitive),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return F.sigmoid(self.out(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain_adverserial(adv, clf, data_loader, optimizer, criterion):\n",
    "    for x, _, z in data_loader:\n",
    "        p_y = clf(x).detach()\n",
    "        adv.zero_grad()\n",
    "        p_z = adv(p_y)\n",
    "        loss = criterion(p_z, z)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv = Adverserial(Z_train.shape[1])\n",
    "adv_criterion = nn.BCELoss()\n",
    "adv_optimizer = optim.Adam(adv.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ADV_EPOCHS = 5\n",
    "\n",
    "for epoch in range(N_ADV_EPOCHS):\n",
    "    pretrain_adverserial(adv, clf, train_loader, adv_optimizer, adv_criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pre_adv_test = adv(pre_clf_test)\n",
    "    \n",
    "y_pre_adv = pd.DataFrame(pre_adv_test.numpy(), columns=Z.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_dists(y_test, Z_test, y_pre_clf, y_pre_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_adv_criterion = nn.BCELoss(reduce=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = torch.Tensor([20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(clf, adv, data_loader, clf_criterion, adv_criterion,\n",
    "          clf_adv_criterion, clf_optimizer, adv_optimizer):\n",
    "    \n",
    "    for x, y, z in data_loader:\n",
    "        p_y = clf(x)\n",
    "\n",
    "        # Train adversarial\n",
    "        adv.zero_grad()\n",
    "        p_adv = adv(p_y)\n",
    "        loss_adv = adv_criterion(p_adv, z)\n",
    "        loss_adv.backward(retain_graph=True)\n",
    "        adv_optimizer.step()\n",
    "        \n",
    "    # Train classifier on last batch\n",
    "    clf.zero_grad()\n",
    "    clf_loss = clf_criterion(p_y, y) - (clf_adv_criterion(adv(p_y), z) * lambdas).sum()\n",
    "    clf_loss.backward()\n",
    "    clf_optimizer.step()\n",
    "    \n",
    "    return clf, adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "N_EPOCH_COMBINED = 100\n",
    "\n",
    "for epoch in range(N_EPOCH_COMBINED):\n",
    "    \n",
    "    clf, adv = train(clf, adv, train_loader, clf_criterion, adv_criterion,\n",
    "                     clf_adv_criterion, clf_optimizer, adv_optimizer)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        clf_pred = clf(test_data.X)\n",
    "        adv_pred = adv(clf_pred)\n",
    "    \n",
    "    y_post_clf = pd.Series(clf_pred.numpy().ravel(), index=y_test.index)\n",
    "    Z_post_adv = pd.DataFrame(adv_pred.numpy(), columns=Z_test.columns)\n",
    "    \n",
    "    if epoch % (N_EPOCH_COMBINED/10) == 0:\n",
    "        plot_dists(y_test, Z_test, y_post_clf, Z_post_adv, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
